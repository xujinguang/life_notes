## HyperLogLog

### 需求

1. UV
2. 关键词搜索
3. 数据分析

### 直觉方法

记录集合中所有不重复的元素集合；当新来一个元素，若中不包含元素，则将加入；否则不加入，计数值就是的元素数量。

可用数据结构：HaspMap，Set，ZSet（底层也是哈希表），B树，bitmap

### 存储元素算法

#### HashMap

1. 计算`value`的`hash`值，然后分配节点并存入`value`.
2. 判断哈希表对应槽位上是否存在元素；
3. 如果有，则遍历比对冲突链表；
4. 如果查找存在，则结束；否则，插入链表结尾；
5. 如果哈希表装填因子变大，则进行`rehash`操作

#### B树

1. 查找树节点，比对`value`值
2. 找到，则放弃插入；否则，分配节点并存入`value`.
3. 执行B树插入操作。
4. 树的节点个数即为元素个数。

#### BitMap

1. 计算value的整形哈希值，以此哈希值为索引设置位图对应`bit`
2. 如果对应`bit`位已经设置为1，则放弃；否则，置位1；
3. 统计位图1的个数，即为元素个数。
4. 为了防止冲突，需要比较均匀的哈希函数，并且根据访问量增加而放大位图。

| 对比项 | HashMap           | B树      | BitMap                                                 |
| ------ | ----------------- | -------- | ------------------------------------------------------ |
| 查找   | 最快O(1),最坏O(n) | O(log^n) | O(1)                                                   |
| 插入   | O(1)              | O(log^n) | O(1)                                                   |
| 存储   | O(n)              | O(n)     | O(n)                                                   |
| 准确度 | 精确              | 精确     | 如果请求id是整形，则比较精确<br>如果id是哈希值，则粗略 |
| 值     | 元素本身          | 元素本身 | 元素本身/哈希值                                        |

很显然，三种方法随着数据量增大而增大是主要问题。查找和插入不是性能的瓶颈。如果只是单纯的统计UV，对于亿万数据量级的存储显得没有必要性。

### 问题

1. 存储空间随元素线性增长，比如亿万数量级的元素；
2. 元素越多，判断是否加入成本越大；
3. 数据合并成本大。

### 非存储元素算法

不追求绝对准确，保证误差控制在一定范围。不存储元素，节省内存。基于概率。

#### Linear Counting

#### LogLog

#### HyperLogLog



### redis中hyperloglog

| cmd     | 时间复杂度 | 功能                 |
| ------- | ---------- | -------------------- |
| pfadd   | O(1)       | 将元素放入hll        |
| pfcount | O(1)~O(N)  | 统计hll中的元素个数  |
| pfmerge | O(N)~const | 合并多个hll到指定hll |

pf是算法发明人的`Philippe Flajolet`的首字母。

#### 12KB

redis中实现用的$$2^{14}=16384$$个桶，每个桶占用 `6`个`bit`,为什么是6个。因为redis将value哈希成`64bit`值，分桶占去14个，剩余50个bit，最坏情况下，低位第一个1出现在第50个bit，那么需要最少6bit ：$$2^{6}=64 > 50$$ 来表示这个位置。所以每个桶用6bit。最后的大小：$$\frac{2^{14} \times 6  (bits)}{2^{13}} = 2 \times 6(KB) = 12KB$$ 