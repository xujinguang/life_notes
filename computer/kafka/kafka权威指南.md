[TOC]



##《Kafka权威指南》

### 第一章 初识kafka

#### 1.1 发布与订阅

​	发布者将消息进行分类，接收者订阅它们；发布和订阅有个消息中心broker

​	什么是技术债务：就是为最初的结构设计所增加的技术成本投入。原始的点对点的数据传输，会形成乱麻的连接。增加中间层，即消息队列是偿还债务的最佳方式。这个消息队列需要支持不同消息的分类，数据的安全，高可用性等等。这个传递消息的中间系统就叫消息系统，一般称为“分布式提交日志”或者“分布式流式平台“，kafka就是其实现之一。

#### 1.2 kafka

​	kafka的数据单元称为消息，类似数据库的数据行或记录。消息由字节构成。这样就是二进制安全的。

​	kafka的消息分批传输，以减少网络开销。批次数据会被压缩。

### 第二章

#### 2.3配置

1. broker.id 标识整数值，默认0，kafka集群里必须唯一
2. port 默认9092,1024以下端口不建议使用
3. zookeeper保存broker的元数据，默认localhost:2181
4. log.dirs 消息落地磁盘，存放日志片段；可以指定多个，按照最少使用原则使用。
5. num.recovery.threads.per.data.dir 线程数数是log.dirs的路径个数乘积
6. auto.create.topics.enable 建议设置false，并显式创建topic。虽然会自动创建，但是无法确认已经存在。

### 第三章  生产者

#### 1. 要求

 	1. 消息的重要度？
 	2. 消息是否允许丢失?
 	3. 重复消息是否接受？
 	4. 延时和吞吐量的要求?

#### 2.生产者过程

1. 创建ProducerRecord 对象，包括主题，分区，键值对,键值对序列化成字节数组
2. 选择分区，将记录发送到批次上
3. 独立的线程将记录批次发送给broker
4. 写入成功返回一个RecordMetaData 对象，包括主题和分区信息，以及分区的偏移量
5. 如果写入失败，重试，重试几次后，返回一个错误

#### 3. 创建kafka生产者

设置属性

1. bootstrap.servers - 指定broker的地址清单，至少两个，容灾
2. key.serializer - 序列化器
3. value.serializer - 序列化器
4. acks = 0、1、all 决定于几个服务器收到时，回复生产者
5. buffer.memory 发送缓存，批量整合发送，节省网络资源，当send超过缓存空间时会被阻塞或者抛出异常，buffer.full设置
6. compression.typ 发送压缩算法：snappy，gzip，lz4
7. retries 当发送失败时重试的次数， retry.backoff.ms配置时间间隔，过快过慢都不友好
8. batch.size 一个批次可以使用的内存大小，字节单位。不一定满了才发送。设置太小，会频繁的发送消息
9. linger.ms 等待批次的时间。会和8结合使用。目的增加吞吐量，缺点时crash了就缓存的消息丢失了。
10. client.id 任意整形，标示来源id
11. max.in.flight.request.per.connection 生产者收到服务器响应之前可以发送多少个消息
12. timeout.ms / request.timeout.ms /metadata.fetch.timeout.ms 超时时间
13. max.block.ms 发送缓冲区满后，send阻塞时间，超时后抛出异常。
14. max.request.size 生产者发送请求单个消息的最大值
15. receive/send.buffer.bytes  socket发送和接收的缓冲区大小。设置-1，使用系统默认值

#### 4.分区

1. kafka的消息时kv结构
2. key可以为空，相同的key会被写到topic的同一分区，因为key作为hash的；因此消费此分区的消费者会消费所有键值相同的消息
3. 不指定key并且使用默认分区，则随机（轮询）选择分区
4. 指定分区的场景就是业务隔离。让消息数据量比较大的隔离到指定分区上去，而避免小客服被大客服影响的局面。


​	相同的键将写到同一个分区；不指定键将随机发送到可用的分区上。由于使用散列对键进行分配分区，如果增加分区就会破坏上面规则，因此，如果使用键来分区需要提前规划好，避免变动分区。

### 第四章 消费者

1. 消费者从属了消费者群组；一个群组里的消费者订阅同一个主题。
2. 消费者少于分区，则一个消费者消费多个分区；如果相等，则一比一关系；如果大于分区，则有消费者闲置。因此，可以创建较多的分区，但是不能让消费者个数多于分区。闲置就是浪费资源。
3. 多个应用程序访问相同主题，创建不同的群组即可，互不影响。
4. 群组中的消费者崩溃后，会离开群组；然后其负责的分区会转移给另外一个消费者，即再平衡。
5. 群组关系通过群组协调器broker负责，通过消费者发送心跳给broker维持消费关系。心跳死亡，则消费者死亡，则触发分区再平衡。
6. 第一个进入群组的是群主，它负责分配分区，分区信息由broker下发；只有群主知道所有分配信息；

#### 1. 创建消费者

​	创建kafkaConsumer 对象，和创建生产者类似，需要1,2,3参数，2,3参数用于反序列化；此外增加group.id参数。指定所属群组ID。

#### 2. 订阅主题

​	调用subscribe方法，参数主题列表。主题也可以使用正则表达式，以方便匹配多个主题。当新主题加入并匹配正则，则触发再平衡。

#### 3.轮询

​	向服务器请求数据。获得了主题；要像鱼儿一样不停轮询，否则会被认为死亡。
poll方法指定超时时间；返回的数据是一个列表；包括主题，分区，偏移量和键值对。最后close关闭消费者，主动死亡，直接触发均衡器。
消费者心跳也是轮询发送出去的。

#### 4.配置

1. fetch.min.bytes 从服务器获取记录的最小字节数
2. fetch.max.wait.ms  broker等待的时间；和1结合
3. max.partition.fetch.bytes 指定每个分区返回给消费者最大字节数，默认1MB；其值要和分区数相关，并且不能太大而影响轮询
4. session.timeout.ms 消费者断开的最大时间，默认3s
5. auto.offset.reset = lates/earliest 偏移量无效时从最新的记录开始读取/从起始位置
6. enable.auto.commit 默认true，可以设置false
7. partition.assignment.strategy = range / roundrobin
8. client.id
9. max.poll.records 
10. eceive/send.buffer.bytes  socket包大小  同上

#### 5. 提交、偏移量

​	更新偏移量的操作称为提交。再平衡后需要重新读取每个分区最后一个次提交的偏移量，从这里继续处理。

​	如果提交的偏移量小于客户端处理的最后一个偏移量，那么中间的消息会被重复处理。反之，则会丢失消息。解决办法就是永恒自己提交。

​	即enable.auto.commit =true，客户端默认5s自动提交一次接收的最大偏移量。但是还有有再平衡的时间窗口无法避免重复消息。	

​	commitSync()将提交由poll返回的最新偏移量。所以处理完poll的记录后，执行它。防止消息丢失。这是是同步阻塞，而且不断重试而且直到成功。避免影响吞吐量，使用异步提交commitAsync();需要用户自己处理提交顺序，一旦顺序错乱会发生重复消息。二者可以携带参数，以提交指定偏移量。

#### 6.定位读取
从特定的偏移量读取，
SeekToBegin、SeekToEnd， seek方法
进程使用结束后，以事物的方式将分区和偏移量更新db，然后如果发生再平衡，可以数据库里恢复。

#### 7.关闭

​	唯一退出循环方式wakeup(),然后捕获wakeuexception

#### 8.独立消费者
指定topic或分区读取
除了不会发生再均衡，也不需要手动查找分区，其他的看起来一切正常。不过要记住，如果主题增加了新的分区，消费者并不会收到通知。所以，要么周期性地调用consumer. partitionsFor()方法来检查是否有新分区加入，要么在添加新分区后重启应用程序。

### 第五章 深入kafka

Kafka的主题被分为多个分区，分区是基本的数据块。分区存储在单个磁盘上，Kafka可以保证分区里的事件是有序的，分区可以在线（可用），也可以离线（不可用）。每个分区可以有多个副本，其中一个副本是首领。所有的事件都直接发送给首领副本，或者直接从首领副本读取事件。其他副本只需要与首领保持同步，并及时复制最新的事件。当首领副本不可用时，其中一个同步副本将成为新首领。

#### 1. 控制器

zookeeper来维护群成员信息。broker的id会注册到zookeeper，删除broker时会删除其注册信息；

第一个在zk注册的broker会成为控制器，并创建一个临时节点。其他broker尝试创建就会失败，保证只有一个控制器。
控制器关闭或异常退出，删除临时节点，并通知到其他broker尝试创建新的控制器。

控制器负责分区首领的选举。第一个进来的broker会创建/controler成功，其余则会收到已存在异常。当首领离开时，则选择一个新的首领并同步新首领信息。

kafka使用zookeeper的临时节点选举控制器。节点加入和退出的时通知控制器，控制器负责节点的接入和离开时首领的选举。使用epoch避免脑裂。脑裂是指两个节点同时认为自己是当前的控制器。

#### 2.复制
Kafka把自己描述成“一个分布式的、可分区的、可复制的提交日志服务”

Kafka使用主题来组织数据，每个主题被分为若干个分区，每个分区有多个副本。

1. 首领 - 每个分区都有一个首领副本，读写都经过的副本，保证数据一致性
2. 跟随 - 仅仅拷贝，为了崩溃时新首领而准备。它请求拷贝数据和客户端消费者一样，而且偏移量总是有序请求。

定义同步：
1. 和zk保持心跳同步
2. 过去10s从首领获取过消息
3. 几乎0延迟

不同步的副本，重新上线后从首领获取最新消息即可变成同步的。
#### 3.请求

生产请求
​	request type + request version + correlation ID + client ID

​	broker 使用Acceptor线程监听每个端口。创建连接转给可变的processor线程处理。processor线程将请求放入请求队列，IO线程处理，处理结果放入响应队列，从响应队列取出消息，返送给客户端。

 	1. 生产者请求 - acks = 0， 1 ， all；0发送broker就不管了。1-分区主副本成功就返回；all-等待分区的所有副本同步后返回。
 	2. 元数据请求 - 为了同步broke首领信息，保证正确的路由。发送给非首领broker会收到错误，此时会触发元数据刷新。
 	3. 获取请求-指定请求大小，为了防止broker返回的数据撑爆客户端内存。这是上限；当然也可以指定下限，当足够多数据时返回，如此减少小数据的网络开销。如果一直没有数据，则指定超时时间来约束。采用0拷贝发送消息——消息从文件直接发送到socket，绕过内存缓存。只有同步所有副本后的消息才能被读取，否则，消息认为是不完整的，不允许读取，因此复制的快慢决定了客户端读取的响应。replica.lag.time.max.ms 设置副本复制消息最大延时。
 	

消费数据
    使用零拷贝数据，直接从日志文件里发送到网络，不经过缓冲区。
    其他数据库会缓存起来。消息系统没有这必要。大部分场景谁会二次消费消息呢？

    可以指定获取消息的条数或者大小：将12-30区间的消息返回给我；当消息数据量达到10kb返回给我；避免频繁的请求。
    不是所有消息都是可以消费的。只有消息还没有被写入所有同步副本之前，是不会发送给消费者。避免首领崩溃后消息丢失。

    偏移量写在了主题分区上不再放在zk上了。

#### 4.物理存储

log.dirs 指定了一个用于存储分区的目录清单

分区的分配保证高可用性，不同broker不同机架最大化。最简单的方式是轮询分配，先分配首领副本，然后是跟随副本。如果有机架，则交替选择。

5 个broker， 5 个分区，复制系数3.则15个副本。编号分别：$$B_{01234}$$，首领副本：$$H_{01234}$$；跟随副本$$F^0_1,F^0_1;F^1_1,F^2_1;$$

无机架如下，规律很简单。

0. $$H_0;F^3_1;F^4_0$$
1. $$H_1;F^4_1;F^0_0$$
2. $$H_2;F^0_1;F^1_0$$
3. $$H_3;F^1_1;F^2_0$$
4. $$H_4;F^2_1;F^3_0$$

有机架则采用交替方式，假设012属于机架A，34属于机架B。则分配的顺序是03142轮询分配；

#### 5.文件

分区会分成若干个片段，以降低大文件查找和删除的开销。每个默认片段大小1g，保存一周。当前正在写入的片段叫活跃片段，活跃片段不会被删除。每天使用一个新片段会删除一个旧的片段。每个片段打开的一个文件，需要OS配置支持打开的文件最大数。

保存的格式依然是二进制，也就是生产的内容直接落地，消费的数据直接发送，目的就是支持0拷贝，可以直接发送。但是有个问题，为了获得更好的性能，发送的数据可能是压缩的。那么如果获取指定offset消息的呢？答案下面的索引。

[ 偏移量+魔数+压缩解压+时间戳+键大小+键+值大小+值 ]

查看工具：bin/kafa-run-class.sh kafa.tools.DumpLogSegments

#### 6.索引

每个分区维护一份索引，索引把偏移量映射到片段文件和偏移量在文件中的位置。索引也被分成片段。删除消息时需要删除索引。索引坏了需要重建索引，删除索引，kafka会自动生成索引。

#### 7.清理
启用了清理功能，broker会启动一个清理管理器线程和多个清理线程，它们负责执行清理任务。
过期的数据可以删除，只保留最新的键，而且每个键唯一，这是干净的片段。kafka启动清理线程来完成这个工作。通过创建map，从旧向新数据扫描和map比较，如果不存在，则新。map怎么创建的？

### 第六章

​	可靠性是系统的属性，在设计系统之初就应该考虑。而且这不是单一系统事情。有时需要作出一些权衡。

kafka的可靠性体现在

1. 分区消息的顺序性；
2. 消息同步所有副本时才算已提交，生产者具有不同的确认策略；
3. 只要有一个副本是活跃的，消息就不会丢失；
4. 消费者只能读取已提交的消息。


#### 1. broker配置
可靠性的配置
1. replication.factor 复制系数，默认3个（包括首领），保证N-1失效后依然可用，但是N越大磁盘占用越大。当然可靠，可用性更强。通过成本和消息重要程度而定；也和副本所在机架部署也有关。再多副本机架跪了也全完蛋。
2. unclean.leader.election - 不完全的首领选举，默认true。解决当首领宕机后副本是不同步的如何处理—— 允许就要承担数据丢失或者数据不一致的风险。否则，等待首领恢复而停服。
3. min.insync.replicas - 最少同步副本。如果不满足，broker会拒绝生产者的消息。因为副本不同步了。

原则：
1. 至少3副本，最好每个副本部署再不同机房机架
2. 如果期望数据不丢失，则设置不完全首领选择为false，并且acks=all
3. 处理完消息之后再提交偏移量

验证：
1. 配置验证
2. 应用程序验证
3. 监控

测试：
1. 首领选举
2. 控制器选取
3. 依次重启broker
4. 不完全首领选举
5. 重启生产者
6. 重启消费者


### 第七章 构建数据管道

1. 及时性
Kafka作为一个基于流的数据平台，提供了可靠且可伸缩的数据存储，可以支持几近实时的数据管道和基于小时的批处理。生产者可以频繁地向Kafka写入数据，也可以按需写入；消费者可以在数据到达的第一时间读取它们，也可以每隔一段时间读取一次积压的数据，消费速率完全取决于消费者自己。

kafka保证至少依次传递，也就是可能会重复。

### 第九章 管理kafka
#### 1. 创建主题

主题名字+复制系数+分区数量
主题名字：
## 《kafka原理剖析》

### 一、背景和架构

#### 1. 创建背景

1. 分布式消息系统

 	2. 诞生于LinkedIn
 	3. 用于活动流（访问量，搜索内容等）和运营数据（CPU、IO、请求量、日志、统计、报表）处理的管道

#### 2.消息系统

1. 解耦，各个模块之间影响最小化；进程A宕机和进程B无关。进程B消费快慢和进程A也没关系；
2. 持久化，避免传统的消息队列消费后就丢弃，当然这个条件只受限于磁盘空间；
3. 扩展性，根据需要动态调整生产者消费者个数而不用关系二者之间的速率依赖；系统的平行扩容；
4. 抗波峰，对于波峰毛刺的鲁棒性，而不用特殊设计；
5. 顺序性，消息的有序性满足特定的场景，比如交易；
6. 缓冲，这个和队列一样的作用，只不过它的缓冲能力更牛逼。可以认为是个无限大小的队列；
7. 异步通信，1,2,5特性就决定其必然具有此特性。

#### 3. 消息系统对比

| 消息系统 | 实现语言    | 特点 | 应用   |
| -------- | ----------- | ---- | ------ |
| Kafka    | scala、java |      |        |
| RabbitMQ | Erlang      |      | 企业级 |
| ZeroMQ   |             |      |        |
| ActiveMQ |             |      |        |
| Redis    | C           |      |        |

#### 4.kafka的设计目标

1. O1复杂度的持久化能力，因为它要具有log功能以及TB级别的海量数据
2. 高吞吐率，在普通的机器上具有100k/s的消息传输
3. 消息分区，分布式消费
4. 离线和在线实时数据处理
5. 水平扩展

#### 5.kafka的架构

- **Broker** - 集群中的服务器；
- **Topic** - 逻辑分类。由于是逻辑分类，同类Topic会存储在一个或多个broker上；每个消息都必须属于一个Topic
- **Patition** - 物理分区；一个分区在磁盘上是一个文件夹；一个Topic具有一个或多个分区
- **Segment** - 片段（.kafka文件），每个分区包括多个segment。并有个索引文件
- **Producer** - 生产者，发布消息（push）到 broker
- **Consumer** - 消费者，从broker读取消息（pull）
- **ConsumerGroup** - 每个消费者属于一个指定的Group

消息被append到分区的segment中，即顺序写文件，顺序写磁盘，具有最高IO效率。

删除过期消息数据提高kafka性能无关，因为删除数据只是优化磁盘空间而已。

broker它是无状态的，读取的状态有consumer自己控制。因此具有最大的自由度读取任意存在的消息。这样设计的好处就是不用为分区加锁，不需要记录那些消息是否被消费过，状态由消费者自己管理，因此提高吞吐量。

同一个Group里的消息只会被消费一次；不同Group之间可以共享消费同一个消息。通过这个策略实现广播和单播。广播存在于不同群组之间，单播体现在组内。

push 模式很难适应消费速率不同的消费者，因为消息发送速率是由 broker 决定的。push 模式的目标是尽可能以最快速度传递消息，但是这样很容易造成 Consumer 来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而 pull 模式则可以根据 Consumer 的消费能力以适当的速率消费消息。

####6.kafka的保证

- At most once 消息可能会丢，但绝不会重复传输
- At least one 消息绝不会丢，但可能会重复传输
- Exactly once 每条消息肯定会被传输一次且仅传输一次，很多时候这是用户所想要的。

| 场景                                          | crash              | 范畴                   |
| --------------------------------------------- | ------------------ | ---------------------- |
| Producer 向 broker 发送消息                   | 无法判断commit状态 | At most once（丢数据） |
| Producer 向 broker 发送消息                   | 幂等性提交         | Exactly once（未实现） |
| Consumer 在从 broker 读取消息先 commit 再处理 | commit时崩溃       | 无影响，恢复继续       |
|                                               | 处理数据时崩溃     | At most once（丢数据） |
| Consumer 在从 broker 读取消息先处理再 commit  | 处理数据时崩溃     | 无影响，恢复继续       |
|                                               | commit时崩溃       | At least one（重复读） |

总之，Kafka 默认保证 At least once，并且允许通过设置 Producer 异步提交来实现 At most once。而 Exactly once 要求与外部存储系统协作，幸运的是 Kafka 提供的 offset 可以非常直接非常容易得使用这种方式。

### 二、kafka 的HA

####1. 一主多备

​	采用了一主多备，主负责读写，备只用于broker宕机时启用。这样设计保证多个副本之间的数据一致性比较简单，也不会存在脑裂的问题。

#### 2.随从pull消息并立刻ACK

这样生产者只需要将消息发给leader，随从从leade哪里和消费者一样去pull消息即可，简化设计。kafka只保证内存数据一致性，不保证磁盘持久化一致性。因为它pull到数据就commit了，如何commit之后崩溃了，那么数据会丢失。这种情况十分少见。所以是一种折中平衡。

#### 3.ACK的备份数

Leader维护ISR，当落后太多或者超时，则从ISR除名；用户决定ACK个数决定commit给消费者

#### 4.全员牺牲恢复方案

- 等待ISR中的任一个Replica“活”过来，并且选它作为Leader
- 选择第一个“活”过来的Replica（不一定是ISR中的）作为Leader

kafka选择的第二个。第一个的劣势就是可能等待时间比较长。第二个的劣势可能数据丢失比较多。



```json
category_id: 1
    mode_id: 3
  mode_name: 亮度
mode_script: function modeproto(args)
local proto = {}
local color = {}
color["red"] = math.modf(args["blue"] * args["transparent"] / 255)
color["green"] = math.modf(args["green"] * args["transparent"] / 255)
color["blue"] = math.modf(args["red"] * args["transparent"] / 255)
color["transparent"] = args["transparent"]
proto["color"] = color
return marshal(proto)
end
-----------------------------
category_id: 1
    mode_id: 4
  mode_name: 多彩
mode_script: function modeproto(args)
local proto = {}
local color = {}
color["blue"] = args["blue"]
color["green"] = args["green"]
color["red"] = args["red"]
color["transparent"] = args["transparent"]
proto["color"] = color
return marshal(proto)
end
```

```json
{
    "desired": {
        "red": "100",
        "green":"100",
        "blue":"100",
        "transparent":50
    }
}
```

```json
{
    "DeviceId": "jlonxvxzoiuaosdnfaf",
    "DeviceType": 1,
    "DeviceMode": 4,
    "AppId": "12000",
    "Args": [
        {"Name": "red", "Value": 100},
        {"Name": "green", "Value": 100},
        {"Name": "blue", "Value": 100},
        {"Name": "transparent", "Value":  50}
    ]
}
```

